{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download the small test dataset first"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If working on Colab or you have gsutil installed on your local machine, try the code block below; otherwise, use the [link](https://storage.googleapis.com/kidney_dataset/test_data.zip) to download the dataset and move it to `/tmp/test_data/` folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copying gs://kidney_dataset/test_data.zip...\n",
      "| [1 files][ 69.9 MiB/ 69.9 MiB]                                                \n",
      "Operation completed over 1 objects/69.9 MiB.                                     \n"
     ]
    }
   ],
   "source": [
    "!mkdir -p /tmp/test_data/\n",
    "!gsutil cp \"gs://kidney_dataset/test_data.zip\" \"/tmp/test_data/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archive:  /tmp/test_data/test_data.zip\n",
      "   creating: /tmp/test_data/hdf5_source/\n",
      "  inflating: /tmp/test_data/hdf5_source/PAS_005_tuft_mask.png  \n",
      "  inflating: /tmp/test_data/hdf5_source/PAS_005.png  \n",
      "  inflating: /tmp/test_data/hdf5_source/PAS_004_tuft_mask.png  \n",
      "  inflating: /tmp/test_data/hdf5_source/PAS_004.png  \n",
      "  inflating: /tmp/test_data/hdf5_source/PAS_003_tuft_mask.png  \n",
      "  inflating: /tmp/test_data/hdf5_source/PAS_003_capsule_mask.png  \n",
      "  inflating: /tmp/test_data/hdf5_source/PAS_003.png  \n",
      "  inflating: /tmp/test_data/hdf5_source/PAS_002_tuft_mask.png  \n",
      "  inflating: /tmp/test_data/hdf5_source/PAS_002.png  \n",
      "  inflating: /tmp/test_data/hdf5_source/PAS_001_tuft_mask.png  \n",
      "  inflating: /tmp/test_data/hdf5_source/PAS_001_capsule_mask.png  \n",
      "  inflating: /tmp/test_data/hdf5_source/PAS_001.png  \n"
     ]
    }
   ],
   "source": [
    "!unzip -o /tmp/test_data/test_data.zip -d /tmp/test_data/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create hdf5 dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data_root = Path(\"/tmp/test_data/hdf5_source/\")\n",
    "output_data_root = Path(\"/tmp/test_data/hdf5_output\")\n",
    "output_data_root.mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from patches_extraction import extract_img_patches, extract_mask_patches, Extractor, crop_and_save_patches_to_hdf5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "extractor = Extractor(resize=0.25, mirror_pad_size=128, patch_size=256, stride_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PosixPath('/tmp/test_data/hdf5_source/PAS_001.png'),\n",
       " PosixPath('/tmp/test_data/hdf5_source/PAS_002.png'),\n",
       " PosixPath('/tmp/test_data/hdf5_source/PAS_003.png'),\n",
       " PosixPath('/tmp/test_data/hdf5_source/PAS_004.png'),\n",
       " PosixPath('/tmp/test_data/hdf5_source/PAS_005.png')]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images = [p for p in input_data_root.glob(\"*.png\") if \"mask\" not in str(p)]\n",
    "images.sort()\n",
    "images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PosixPath('/tmp/test_data/hdf5_source/PAS_001_tuft_mask.png'),\n",
       " PosixPath('/tmp/test_data/hdf5_source/PAS_002_tuft_mask.png'),\n",
       " PosixPath('/tmp/test_data/hdf5_source/PAS_003_tuft_mask.png'),\n",
       " PosixPath('/tmp/test_data/hdf5_source/PAS_004_tuft_mask.png'),\n",
       " PosixPath('/tmp/test_data/hdf5_source/PAS_005_tuft_mask.png')]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "masks = [p for p in input_data_root.glob(\"*tuft_mask.png\")]\n",
    "masks.sort()\n",
    "masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('/tmp/test_data/hdf5_output/PAS_glom_train.h5')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hdf5_dataset_fname = output_data_root / \"PAS_glom_train.h5\"\n",
    "hdf5_dataset_fname"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/henryhuang/.conda/envs/pytorch/lib/python3.7/site-packages/sklearn/utils/deprecation.py:86: FutureWarning: Function extract_patches is deprecated; The function feature_extraction.image.extract_patches has been deprecated in 0.22 and will be removed in 0.24.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((144, 256, 256, 3), 144)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test the function of image extraction helper function\n",
    "patches, image_indices = extract_img_patches(images[0], extractor)\n",
    "patches.shape, len(image_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((144, 256, 256, 3), 119)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test the function of mask extraction helper function\n",
    "mask_patches, mask_indices = extract_mask_patches(masks[0],extractor)\n",
    "mask_patches.shape, len(mask_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test the main function used for generating hdf5 file\n",
    "crop_and_save_patches_to_hdf5(hdf5_dataset_fname, images, masks, extractor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PAS_glom_train.h5\n"
     ]
    }
   ],
   "source": [
    "!ls $output_data_root"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data as torch Dataset and Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataset import Dataset\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.transforms import transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters for augmentations and training\n",
    "patch_size = 256\n",
    "device = torch.device(\"cuda:0\")\n",
    "edge_weight = 1.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#note that since we need the transofrmations to be reproducible for both masks and images\n",
    "#we do the spatial transformations first, and afterwards do any color augmentations\n",
    "img_transform = transforms.Compose([\n",
    "    transforms.ToPILImage(),\n",
    "    transforms.RandomVerticalFlip(),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomCrop(size=(patch_size,patch_size),pad_if_needed=True), #these need to be in a reproducible order, first affine transforms and then color\n",
    "    transforms.RandomResizedCrop(size=patch_size,scale=(0.8, 1.2)),\n",
    "    transforms.RandomRotation(180),\n",
    "    \n",
    "    #randomly pick a color augmentation\n",
    "    transforms.RandomChoice([\n",
    "    transforms.ColorJitter(brightness=0, contrast=0, saturation=0, hue=.2),\n",
    "    transforms.ColorJitter(brightness=0.3, contrast=0, saturation=0, hue=0),\n",
    "    transforms.ColorJitter(brightness=0.1, contrast=0, saturation=0.2, hue=0),\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0, saturation=0.1, hue=0.2),\n",
    "    transforms.RandomGrayscale()]),\n",
    "    transforms.ToTensor()\n",
    "    ])\n",
    "\n",
    "\n",
    "mask_transform = transforms.Compose([\n",
    "    transforms.ToPILImage(),\n",
    "    transforms.RandomVerticalFlip(),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomCrop(size=(patch_size,patch_size),pad_if_needed=True), #these need to be in a reproducible order, first affine transforms and then color\n",
    "    transforms.RandomResizedCrop(size=patch_size,scale=(0.8, 1.2)),\n",
    "    transforms.RandomRotation(180),\n",
    "    transforms.ToTensor()\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "hdf5_dataset_fname = Path(\"/tmp/test_data/hdf5_output/PAS_glom_train.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = Dataset(hdf5_dataset_fname, \n",
    "                  img_transform=img_transform, \n",
    "                  mask_transform=mask_transform, \n",
    "                  use_edge_mask=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = DataLoader(dataset, batch_size=8, shuffle=True, num_workers=2, pin_memory=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simulate the training procedure to test the functionality of dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# just for testing dataloader, not applying gradient descent here\n",
    "loss = torch.nn.CrossEntropyLoss(reduction='none')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: torch.Size([8, 3, 256, 256]), Dtype: torch.float32\n",
      "Shape: torch.Size([8, 256, 256]), Dtype: torch.int64\n",
      "Shape: torch.Size([8, 256, 256]), Dtype: torch.float32\n",
      "Batch 0 has loss: 0.7136338949203491\n",
      "Batch 1 has loss: 0.713422417640686\n",
      "Batch 2 has loss: 0.7133139371871948\n",
      "Batch 3 has loss: 0.7133567333221436\n",
      "Batch 4 has loss: 0.7135315537452698\n",
      "Batch 5 has loss: 0.7135619521141052\n",
      "Batch 6 has loss: 0.713448166847229\n",
      "Batch 7 has loss: 0.713767409324646\n",
      "Batch 8 has loss: 0.7139379382133484\n",
      "Batch 9 has loss: 0.7135822772979736\n",
      "Batch 10 has loss: 0.7134979963302612\n",
      "Batch 11 has loss: 0.7140174508094788\n",
      "Batch 12 has loss: 0.7135435342788696\n",
      "Batch 13 has loss: 0.7138286828994751\n",
      "Batch 14 has loss: 0.7135250568389893\n",
      "Batch 15 has loss: 0.7136993408203125\n",
      "Batch 16 has loss: 0.713544487953186\n",
      "Batch 17 has loss: 0.7137070894241333\n",
      "Batch 18 has loss: 0.7136034965515137\n",
      "Batch 19 has loss: 0.7132987380027771\n",
      "Batch 20 has loss: 0.7140078544616699\n",
      "Batch 21 has loss: 0.7136460542678833\n",
      "Batch 22 has loss: 0.7138321399688721\n",
      "Batch 23 has loss: 0.7131334543228149\n",
      "Batch 24 has loss: 0.7139231562614441\n",
      "Batch 25 has loss: 0.7134441137313843\n",
      "Batch 26 has loss: 0.7137926816940308\n",
      "Batch 27 has loss: 0.7135178446769714\n",
      "Batch 28 has loss: 0.7136841416358948\n",
      "Batch 29 has loss: 0.7140493392944336\n",
      "Batch 30 has loss: 0.7138510346412659\n",
      "Batch 31 has loss: 0.7136781811714172\n",
      "Batch 32 has loss: 0.7134726047515869\n",
      "Batch 33 has loss: 0.7136335372924805\n",
      "Batch 34 has loss: 0.7136739492416382\n",
      "Batch 35 has loss: 0.7137733697891235\n",
      "Batch 36 has loss: 0.713492751121521\n",
      "Batch 37 has loss: 0.7136291861534119\n",
      "Batch 38 has loss: 0.7137497067451477\n",
      "Batch 39 has loss: 0.7139605283737183\n",
      "Batch 40 has loss: 0.7134747505187988\n",
      "Batch 41 has loss: 0.7139396667480469\n",
      "Batch 42 has loss: 0.7139456868171692\n",
      "Batch 43 has loss: 0.713593602180481\n",
      "Batch 44 has loss: 0.7132607698440552\n",
      "Batch 45 has loss: 0.7135639190673828\n",
      "Batch 46 has loss: 0.7137328386306763\n",
      "Batch 47 has loss: 0.7135035991668701\n",
      "Batch 48 has loss: 0.7136854529380798\n",
      "Batch 49 has loss: 0.7142828702926636\n",
      "Batch 50 has loss: 0.7136613726615906\n",
      "Batch 51 has loss: 0.7136821746826172\n",
      "Batch 52 has loss: 0.7134313583374023\n",
      "Batch 53 has loss: 0.7138180732727051\n",
      "Batch 54 has loss: 0.7139266133308411\n",
      "Batch 55 has loss: 0.7136682271957397\n",
      "Batch 56 has loss: 0.7138872146606445\n",
      "Batch 57 has loss: 0.713692843914032\n"
     ]
    }
   ],
   "source": [
    "for i, data in enumerate(dataloader):\n",
    "    img, mask, edge_mask = list(map(lambda x: x.to(device), data))\n",
    "    \n",
    "    # generate a naive prediction using binary random samples\n",
    "    output = torch.rand(size=(mask.shape[0], 2, *mask.shape[1:])).to(device) # [N, Nclass, H, W]\n",
    "    \n",
    "    loss_matrix = loss(output, mask)\n",
    "    loss_val = (loss_matrix * (edge_weight**edge_mask)).mean()\n",
    "    \n",
    "    if i == 0:\n",
    "        list(map(lambda x: print(f\"Shape: {x.shape}, Dtype: {x.dtype}\"), data))\n",
    "    print(f\"Batch {i} has loss: {loss_val}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
