{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "collage_generator_demo_with_coco.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ey_Hx-ePmnEh"
      },
      "source": [
        "!git clone https://github.com/Auto-annotation-of-Pathology-Images/AAPI_code"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W-yuALs407YY"
      },
      "source": [
        "# install dependencies: \n",
        "!pip install pyyaml==5.1\n",
        "import torch, torchvision\n",
        "print(torch.__version__, torch.cuda.is_available())\n",
        "!gcc --version\n",
        "# opencv is pre-installed on colab"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FqMjaSS64IBR"
      },
      "source": [
        "# install detectron2: (Colab has CUDA 10.1 + torch 1.7)\n",
        "# See https://detectron2.readthedocs.io/tutorials/install.html for instructions\n",
        "import torch\n",
        "assert torch.__version__.startswith(\"1.7\")\n",
        "!pip install detectron2 -f https://dl.fbaipublicfiles.com/detectron2/wheels/cu101/torch1.7/index.html\n",
        "# exit(0)  # After installation, you need to \"restart runtime\" in Colab. This line can also restart runtime"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OA7gZdr8mrB0",
        "scrolled": true
      },
      "source": [
        "from AAPI_code.Collage_generator import collage_generator\n",
        "from AAPI_code.format_converter import format_converter\n",
        "from AAPI_code.Collage_generator.utils import *\n",
        "from PIL import Image\n",
        "from tqdm.notebook import tqdm\n",
        "import json"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CfG_O5NjHaX5"
      },
      "source": [
        "# if you want\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SZmKhwTvom_0"
      },
      "source": [
        "# collage_generator setting"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wmyh2P-Gm11T"
      },
      "source": [
        "col_gen = collage_generator(label_list= [], \n",
        "                            canvas_size=(3000,3000),\n",
        "                            example_image = \"/content/AAPI_code/data/vignettes/background/11000_16000_0_background.png\",\n",
        "                            gaussian_noise_constant = 5,\n",
        "                            cluster_size = (2200,2200)\n",
        "                            )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EDl5NMWSmhRi"
      },
      "source": [
        "col_gen.import_images_from_directory_original_size(root_path=\"/content/AAPI_code/data/vignettes/train\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DFRq28Yu_tyz"
      },
      "source": [
        "# Generation Example, please have format = \"COCO\""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CVZzEuaqDps-"
      },
      "source": [
        "collage,mask, color_dict, label_dict = col_gen.generate(item_num= 5,\n",
        "                                                        ratio_dict={\"cluster\":0.2, \"artery\": 0.5, 'arteriole': 0.3},\n",
        "                                                        background_color = False,\n",
        "                                                        format = 'COCO'\n",
        "                                                        )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ULpzzbQU5fsX"
      },
      "source": [
        "# Keep the mask as image\n",
        "\n",
        "It makes further cut possible, once we need to run Detectron2, we parse all the data into the correct format\n",
        "\n",
        "Original saving:\n",
        "1. Collage\n",
        "2. Mask(saved in different color, to distinguish individual instance)\n",
        "3. Dict(the dict of each individual color to the corresponding class)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e6CV2_Jc3h9j"
      },
      "source": [
        "fc = format_converter()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O7Ym_XxZ2lAo"
      },
      "source": [
        "fc.save_coco_raw(collage = collage, \n",
        "                 mask = mask, \n",
        "                 color_dict = color_dict, \n",
        "                 root_path =\"output\", \n",
        "                 name = 'train')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bqqcnwav3nE0"
      },
      "source": [
        "collage, mask, color_dict = fc.read_coco_raw(root_path = \"output\", name = 'train')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vxx4gxb46rz7"
      },
      "source": [
        "Save the collage, mask into patches, in a rolling window practice\n",
        "\n",
        "in the saving path, there're:\n",
        "1. each individual patch with it's mask\n",
        "2. the copy of color dict\n",
        "\n",
        "This method can be used on both training and testing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zMVtMnlYxmQt"
      },
      "source": [
        "# this size and offset is using normal human understanding (width, height), not pixel size\n",
        "# feel free to use np.array([1024,768])\n",
        "fc.save_sliding_window(collage = collage,\n",
        "                       mask = mask,\n",
        "                       color_dict = color_dict,\n",
        "                       image_name = \"image_2\",\n",
        "                       saving_path = \"window_slide\",\n",
        "                       window_size = np.array([1024,1024]),\n",
        "                       offset = np.array([256,256]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x9l2o1Kq7N7W"
      },
      "source": [
        "For each time training with Detectron, parse the saved files, it's okay to save multiple {image_name}'s file into one path, parse_detectron can handle that"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dMIX03yYPduc"
      },
      "source": [
        "training_set = fc.parse_detectron(path = \"window_slide\")\n",
        "test_set = fc.parse_detectron(path = \"window_slide_1\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "js9UbMYq87ew"
      },
      "source": [
        "# Detectron2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tKiU3enn4Kml"
      },
      "source": [
        "# Some basic setup:\n",
        "# Setup detectron2 logger\n",
        "import detectron2\n",
        "from detectron2.utils.logger import setup_logger\n",
        "setup_logger()\n",
        "\n",
        "# import some common libraries\n",
        "import numpy as np\n",
        "import os, json, cv2, random\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "# import some common detectron2 utilities\n",
        "from detectron2 import model_zoo\n",
        "from detectron2.engine import DefaultPredictor\n",
        "from detectron2.config import get_cfg\n",
        "from detectron2.utils.visualizer import Visualizer\n",
        "from detectron2.data import MetadataCatalog, DatasetCatalog"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yuj-SRof0O7v"
      },
      "source": [
        "Detectron use string as the id of dataset，you need：\n",
        "1. register(str name, func dataset) onto Datacatalog, f need to be a function returning json list\n",
        "2. get your dataset on MetadataCatalog with the name，set its class，notice that our label is 1-5，you need a background in the front\n",
        "3. prepare the metadata"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4eFIiCKb4NbT"
      },
      "source": [
        "DatasetCatalog.register(\"AAPI_train\",lambda p=\"window_slide\": training_set)\n",
        "MetadataCatalog.get(\"AAPI_train\").set(thing_classes=['background','arteriole', 'artery', 'distal_tubule', 'glomerulus', 'proximal_tubule'])\n",
        "AAPI_metadata = MetadataCatalog.get(\"AAPI_train\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MRmxIdfN1PGo"
      },
      "source": [
        "Preview some input"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JLbphfpd9wHm"
      },
      "source": [
        "def preview(dataset_dicts, metadata, preview = 3):\n",
        "    for d in random.sample(dataset_dicts, preview):\n",
        "        img = cv2.imread(d[\"file_name\"])\n",
        "        visualizer = Visualizer(img[:, :, ::-1], metadata=AAPI_metadata, scale=0.5)\n",
        "        out = visualizer.draw_dataset_dict(d)\n",
        "        cv2_imshow(out.get_image()[:, :, ::-1])\n",
        "\n",
        "preview(dataset_dicts = training_set, metadata = AAPI_metadata, preview = 3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TXl5CMYN1umT"
      },
      "source": [
        "settings and training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OtfTF6vH91Pf"
      },
      "source": [
        "from detectron2.engine import DefaultTrainer\n",
        "\n",
        "cfg = get_cfg()\n",
        "cfg.merge_from_file(model_zoo.get_config_file(\"COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml\"))\n",
        "cfg.DATASETS.TRAIN = (\"AAPI_train\",)\n",
        "cfg.DATASETS.TEST = ()\n",
        "cfg.DATALOADER.NUM_WORKERS = 2\n",
        "cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(\"COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml\")  # Let training initialize from model zoo\n",
        "cfg.SOLVER.IMS_PER_BATCH = 2\n",
        "cfg.SOLVER.BASE_LR = 0.00025  # pick a good LR\n",
        "cfg.SOLVER.MAX_ITER = 1000    # 1000 iterations seems good enough for this toy dataset; you will need to train longer for a practical dataset\n",
        "cfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE = 32   # faster, and good enough for this toy dataset (default: 512)\n",
        "cfg.MODEL.ROI_HEADS.NUM_CLASSES = 6  # only has one class (ballon). (see https://detectron2.readthedocs.io/tutorials/datasets.html#update-the-config-for-new-datasets)\n",
        "\n",
        "os.makedirs(cfg.OUTPUT_DIR, exist_ok=True)\n",
        "trainer = DefaultTrainer(cfg) \n",
        "trainer.resume_or_load(resume=False)\n",
        "trainer.train()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BuLOwsmzHWQG"
      },
      "source": [
        "# Look at training curves in tensorboard:\n",
        "%load_ext tensorboard\n",
        "%tensorboard --logdir output"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6TD-lmul8HJn"
      },
      "source": [
        "Save the model: model is automatically saved at the following path"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oUE18Je0T9RS"
      },
      "source": [
        "# Inference should use the config with parameters that are used in training\n",
        "# cfg now already contains everything we've set previously. We changed it a little bit for inference:\n",
        "cfg.MODEL.WEIGHTS = os.path.join(cfg.OUTPUT_DIR, \"model_final.pth\")  # path to the model we just trained\n",
        "print(cfg.MODEL.WEIGHTS)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U-P8hOpu8DHd"
      },
      "source": [
        "Run prediction"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SRdUqwrX8BCj"
      },
      "source": [
        "DatasetCatalog.register(\"AAPI_test\",lambda p=\"window_slide_test\": test_test)\n",
        "MetadataCatalog.get(\"AAPI_test\").set(thing_classes=['background','arteriole', 'artery', 'distal_tubule', 'glomerulus', 'proximal_tubule'])\n",
        "AAPI_metadata = MetadataCatalog.get(\"AAPI_test\")# train and test doesn't matter"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vWjF9GtrDXG4"
      },
      "source": [
        "cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.3   # set a custom testing threshold\n",
        "predictor = DefaultPredictor(cfg)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HJ6s-VMnUGji"
      },
      "source": [
        "from detectron2.utils.visualizer import ColorMode\n",
        "\n",
        "for d in random.sample(test_set, 3):    \n",
        "    im = cv2.imread(d[\"file_name\"])\n",
        "    outputs = predictor(im)  # format is documented at https://detectron2.readthedocs.io/tutorials/models.html#model-output-format\n",
        "    v = Visualizer(im[:, :, ::-1],\n",
        "                   metadata=AAPI_metadata, \n",
        "                   scale=0.5, \n",
        "                   instance_mode=ColorMode.IMAGE_BW   # remove the colors of unsegmented pixels. This option is only available for segmentation models\n",
        "    )\n",
        "    out = v.draw_instance_predictions(outputs[\"instances\"].to(\"cpu\"))\n",
        "    cv2_imshow(out.get_image()[:, :, ::-1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NOnX40cgDdqW"
      },
      "source": [
        "Predict on any image"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3evDqun_dNUS"
      },
      "source": [
        "def predict(image):\n",
        "    \"\"\"\n",
        "    image can ba a path or a np.ndarray\n",
        "    \"\"\"\n",
        "    if isinstance(image, str):\n",
        "        image = cv2.imread(image)\n",
        "    outputs = predictor(image)\n",
        "    instances = outputs[\"instances\"]\n",
        "    return instances"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kzhF9tPAEBAY"
      },
      "source": [
        "pred_instance = predict(im)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MSmoeHH9c_HX"
      },
      "source": [
        "category_3_detections = pred_instance[pred_instance.pred_classes == 3]\n",
        "confident_detections = pred_instance[pred_instance.scores > 0.9]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cM_FmMGsdQ2F"
      },
      "source": [
        "category_3_detections.pred_masks"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5WJWGbhyaOau"
      },
      "source": [
        "plt.imshow(output.cpu().numpy())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y1cQk-Mjczf2"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}